{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da914d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = [\"Title: Benefits of GraphQL in SaaS \\n GraphQL allows SaaS applications to fetch exactly the data they need, reducing over-fetching and under-fetching. It enables faster front-end development due to predictable APIs and strong typing. Its introspection features and tooling improve developer productivity.\",\n",
    "#     \"Title: When to Use REST vs GraphQLREST \\n APIs work well for simple CRUD operations and caching. GraphQL is better for complex queries and flexible frontend needs. Enterprises choose based on data shape complexity and team expertise.\",\n",
    "#     \"Title: Top Use Cases for GraphQL in Enterprises \\n Enterprises use GraphQL for building unified API layers, enabling federated microservices, and accelerating frontend iteration. It's especially useful in headless CMS, e-commerce platforms, and internal tooling.0\",\n",
    "#     \"Title: Serverless Computing for Startups \\n Serverless architectures like AWS Lambda reduce operational costs and complexity. Startups benefit from auto-scaling, no infrastructure management, and pay-as-you-go pricing models.\",\n",
    "#     \"Title: DevOps in Modern SaaS Development \\n DevOps combines software development with IT operations to shorten the system development life cycle. It enables continuous integration and deployment, fast iterations, and increased software reliability.\",\n",
    "#     \"Title: Benefits of Microservices \\n Microservices promote modularity, scalability, and easier maintenance. They allow independent deployment of services and improve fault isolation across components in large systems.\",\n",
    "#     \"Title: Challenges in Using GraphQL \\n Despite its flexibility, GraphQL introduces challenges like complex caching, rate-limiting, and overexposure of schema internals. It also demands new skills and tooling for monitoring and security.\",\n",
    "#     \"Title: Using AI for Customer Support \\n AI tools like chatbots and virtual agents reduce response times and increase availability. NLP-powered systems can resolve common issues without human intervention, improving scalability and user satisfaction.\",\n",
    "#     \"Title: LLMs in Knowledge Management \\n Large Language Models can summarize documents, extract insights, and provide semantic search. Enterprises are integrating LLMs into their knowledge workflows to surface relevant information faster.\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb42f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for text in texts:\n",
    "#     i += 1 \n",
    "#     with open(f\"data/doc_0{i}.txt\", \"a\") as f:\n",
    "#         f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f8826",
   "metadata": {},
   "source": [
    "### START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f457e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.graph import END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain.document_loaders import TextLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b4c6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OllamaEmbeddings(model=\"mahonzhan/all-MiniLM-L6-v2\")\n",
    "llm = ChatGroq(model=\"llama3-70b-8192\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad50c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"data\")\n",
    "# CHROMA_DIR = \"chroma\"\n",
    "def load_documents():\n",
    "    documents = []\n",
    "\n",
    "    for file in data_dir.glob(\"*\"):\n",
    "        if file.suffix == \".txt\":\n",
    "            loader = TextLoader(str(file), encoding=\"utf-8\")\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "        elif file.suffix == \".pdf\":\n",
    "            loader = PyMuPDFLoader(str(file))\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "    return documents\n",
    "\n",
    "def split_documents(documents):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    return splitter.split_documents(documents)\n",
    "\n",
    "def get_vectorstore(CHROMA_DIR, embedder):\n",
    "    if Path(CHROMA_DIR).exists():\n",
    "        return Chroma(persist_directory=CHROMA_DIR, embedding_function=embedder)\n",
    "    \n",
    "    docs = load_documents()\n",
    "    docs_split = split_documents(docs)\n",
    "    vector_store = Chroma(\n",
    "        embedding_function=embedding,\n",
    "        persist_directory=CHROMA_DIR,\n",
    "    )\n",
    "    vector_store.add_documents(documents=docs_split)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8424a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = get_vectorstore(\"chroma\", embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6df9bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tool\n",
    "# def retrieve(query: str):\n",
    "#     \"\"\"Retrieve information related to a query.\"\"\"\n",
    "#     print(\"==== [RETRIEVE] ====\")\n",
    "#     retrieved_docs = vectordb.similarity_search(query, k=4)\n",
    "#     serialized = \"\\n\\n\".join(\n",
    "#         (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "#         for doc in retrieved_docs\n",
    "#     )\n",
    "#     print\n",
    "#     return {\n",
    "#         \"content\": \"\\n\\n\".join(serialized),\n",
    "#         \"sources\": retrieved_docs\n",
    "#     }\n",
    "# @tool(response_format=\"content_and_artifact\")\n",
    "# def retrieve(query: str):\n",
    "#     \"\"\"Retrieve information related to a query.\"\"\"\n",
    "#     print(\"==== [RETRIEVE] ====\")\n",
    "#     retrieved_docs = vectordb.similarity_search(query, k=4)\n",
    "#     serialized = \"\\n\\n\".join(\n",
    "#         (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "#         for doc in retrieved_docs\n",
    "#     )\n",
    "    \n",
    "#     return serialized, retrieved_docs\n",
    "\n",
    "@tool\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    print(\"==== [RETRIEVE] ====\")\n",
    "    docs = vectordb.similarity_search(query, k=3)\n",
    "\n",
    "    # Convert document sources to just strings\n",
    "    sources = []\n",
    "    full_content = []\n",
    "\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\", \"unknown\")\n",
    "        sources.append(src)\n",
    "        full_content.append(f\"[Source: {src}]\\n{doc.page_content}\")\n",
    "    test = {\n",
    "        \"content\": \"\\n\\n\".join(full_content),\n",
    "        \"sources\": sources\n",
    "    }\n",
    "    print(test)\n",
    "    return {\n",
    "        \"content\": \"\\n\\n\".join(full_content),\n",
    "        \"sources\": sources\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99d7a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_or_respond_prompt = \"\"\"\n",
    "# # Role\n",
    "# You are a highly skilled and experienced **LangGraph conversational agent controller**. You expertly decide, for each incoming user message, whether to invoke a tool_call or to respond directly. Your judgment is precise, consistent, and optimized for maximizing conversational accuracy and relevance in multi-turn LangGraph architectures.\n",
    "\n",
    "# # Task\n",
    "# For each incoming user message, perform the following step-by-step process to decide whether to trigger a tool_call or to respond directly:\n",
    "# 1. **Carefully analyze** the current user message and its intent.\n",
    "# 2. **Review the chat history** provided in `state[\"messages\"]` to understand if the user is following up on a previous answer or introducing a new information request.\n",
    "# 3. If the message asks for **new external data** (e.g., information present only in the tool-retrievable data), decide to **trigger a tool_call**.\n",
    "# 4. If the message is a **clarification, summary request, rephrased follow-up**, or conversational question based on already provided information, decide to **respond directly** without a tool_call.\n",
    "# 5. Produce a single decision: `Tool Call` or `No Tool Call` based on this analysis.\n",
    "\n",
    "# # Specifics\n",
    "# - This task is **critical** to ensure the accuracy and responsiveness of our LangGraph-based conversational system — your diligent and thoughtful analysis is highly valued.\n",
    "# - Prioritize providing decisions that ensure the **best possible user experience** in multi-turn conversations.\n",
    "# - Remember: over-retrieving leads to **redundancy** and can confuse the conversation. Responding without tool_call when appropriate makes the assistant feel more natural and helpful.\n",
    "# - Be especially cautious with **follow-up questions** — these often do not require a new tool_call.\n",
    "# - Your expertise in making these decisions will directly contribute to the success and user satisfaction of our AI application.\n",
    "\n",
    "# # Context\n",
    "# Our company is building an **advanced Retrieval-Augmented Generation (RAG) architecture using LangGraph**.  \n",
    "# Within this architecture, a function called `query_or_respond` is responsible for deciding whether the model should:\n",
    "# - trigger a **tool_call** (via the `retrieve` tool)  \n",
    "# or\n",
    "# - simply **respond directly** using the conversation history.  \n",
    "\n",
    "# The system must optimize for **naturalness**, **efficiency**, and **accuracy**:\n",
    "# - Do **not overuse tool_calls** — use them only when necessary to retrieve genuinely new data.\n",
    "# - Prioritize **fluid conversational flow** for follow-ups or clarifications.\n",
    "# - Our chat architecture stores prior messages in `state[\"messages\"]`, which the model can leverage for context.  \n",
    "# You will act as the controller guiding this decision point with great precision and care.\n",
    "\n",
    "# # Examples\n",
    "# ## Example 1\n",
    "# Q: What are the latest news about ai provided in the docs?  \n",
    "# A: Tool Call  \n",
    "\n",
    "# ## Example 2\n",
    "# Q: Can you resume your previous answer.  \n",
    "# A: No Tool Call  \n",
    "\n",
    "# # Notes\n",
    "# - Provide only one of the following outputs: **\"Tool Call\"** or **\"No Tool Call\"**.\n",
    "# - Be especially mindful that follow-up clarifications or \"what did you say\" types of messages should result in **No Tool Call**.\n",
    "# - New factual queries or requests for external data should result in a **Tool Call**.\n",
    "# - Do not include explanations or any other text in your answer — only output the decision label (\"Tool Call\" or \"No Tool Call\").  \n",
    "# - Remember: your accuracy in this decision point is critical to system performance and user satisfaction.\n",
    "# \"\"\"\n",
    "\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    print(\"==== [QUERY OR RESPOND] ====\")\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "tools = ToolNode([retrieve])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff75043",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prompt = \"\"\"\n",
    "# Role\n",
    "You are a highly skilled and trustworthy **retrieval-based question answering assistant**. Your role is to answer user questions **using only the provided documents**. You do not rely on your own general knowledge or assumptions. You answer strictly based on the retrieved context and never guess.\n",
    "\n",
    "# Task\n",
    "Answer each user question using only the provided context documents by following this step-by-step process:\n",
    "1. Carefully **read and understand the user’s question**.\n",
    "2. Analyze the provided context documents for **relevant information**.\n",
    "3. If the answer can be found in the documents, **quote or paraphrase** the information clearly and accurately.\n",
    "4. If the answer **cannot** be found in the documents, respond clearly that the answer is not available in the provided context.\n",
    "5. Never guess or generate information that is not grounded in the retrieved text.\n",
    "\n",
    "# Specifics\n",
    "- This task is extremely important to the **accuracy, reliability, and safety** of our RAG system — your precision is deeply appreciated.\n",
    "- You must act with integrity and caution. If an answer is **not present**, clearly communicate that instead of fabricating one.\n",
    "- Be concise but thorough. Use quotes when appropriate.\n",
    "- Your honest judgment protects our users and builds trust in our system.\n",
    "\n",
    "# Context\n",
    "Our company uses a LangGraph-based RAG system that passes **retrieved documents** into this function. The function must generate a final answer that:\n",
    "- Is **only** based on the content of the retrieved docs\n",
    "- **Refuses** to answer if the content is not present\n",
    "- **Does not hallucinate** or generate based on prior messages or general model knowledge\n",
    "\n",
    "This function is part of our mission to provide **grounded**, **honest**, and **context-aware** AI answers.  \n",
    "The variable `docs` contains the list of relevant context documents retrieved from our vector store.\n",
    "The following are the retrieved documents you must use as your only source of truth:\n",
    "\n",
    "{docs_content}\n",
    "\n",
    "# Examples\n",
    "## Example 1\n",
    "Q: What year was the product AlphaX first launched?  \n",
    "Docs:  \n",
    "- \"AlphaX was released in 2019 and quickly gained popularity due to its advanced features.\"  \n",
    "A: AlphaX was first launched in 2019.\n",
    "\n",
    "## Example 2\n",
    "Q: What is the current CEO's name of our company?  \n",
    "Docs:  \n",
    "- \"The company was founded by Samir Haddad and later expanded into Europe.\"  \n",
    "A: Sorry, I could not find the answer in the provided context.\n",
    "\n",
    "## Example 3\n",
    "Q: Does the report mention anything about carbon emissions in 2023?  \n",
    "Docs:  \n",
    "- \"The 2023 sustainability report showed a 12% drop in carbon emissions compared to 2022.\"  \n",
    "A: Yes, the 2023 sustainability report mentions a 12% drop in carbon emissions compared to 2022.\n",
    "\n",
    "## Example 4\n",
    "Q: What are the three main pillars of the initiative?  \n",
    "Docs:  \n",
    "- \"The initiative is based on three pillars: transparency, collaboration, and innovation.\"  \n",
    "A: The three main pillars of the initiative are transparency, collaboration, and innovation.\n",
    "\n",
    "## Example 5  \n",
    "Q: Who won the Nobel Prize in Chemistry in 2021?  \n",
    "Docs:  \n",
    "- \"This document focuses on the economic impact of vaccine distribution in 2021.\"  \n",
    "A: Sorry, I could not find the answer in the provided context.\n",
    "\n",
    "# Notes\n",
    "- Do **not** use external knowledge under any circumstance.\n",
    "- Always return factual responses **only** grounded in the provided documents.\n",
    "- If the answer is not explicitly or implicitly found in the docs, respond:  \n",
    "  **\"Sorry, I could not find the answer in the provided context.\"**\n",
    "- Do not attempt to guess or fabricate missing information.\n",
    "- Trust only the given context — that’s your sole source of truth.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e425073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    print(\"==== [GENERATE] ====\")\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        generate_prompt.format(docs_content=docs_content)\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daba7a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedMemorySaver(MemorySaver):\n",
    "    def __init__(self, max_messages=20):\n",
    "        super().__init__()\n",
    "        self.max_messages = max_messages\n",
    "    \n",
    "    def save(self, state):\n",
    "        messages = state[\"messages\"]\n",
    "        # Keep only last N messages\n",
    "        state[\"messages\"] = messages[-self.max_messages:]\n",
    "        super().save(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6abdf82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=WindowedMemorySaver(max_messages=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f3689f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6baa18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_message = \"Who is DOnald Trump?\"\n",
    "\n",
    "# config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "# for step in graph.stream(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "#     stream_mode=\"values\",\n",
    "#     config=config,\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd56884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_message = \"WHat did you say?\"\n",
    "\n",
    "# config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "# for step in graph.stream(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "#     stream_mode=\"values\",\n",
    "#     config=config,\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6840f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\"configurable\": {\"thread_id\": \"abc12\"}}\n",
    "# user_query = \"What are benefits of GraphQL in SaaS?\"\n",
    "# state = {\"messages\": [{\"role\": \"user\", \"content\": user_query}]}\n",
    "\n",
    "# final_state = graph.invoke(state, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f85c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "170f8ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# for msg in final_state[\"messages\"]:\n",
    "#     if msg.type == \"tool\":\n",
    "#         content_dict = json.loads(msg.content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06c81065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "def extract_sources(state: MessagesState):\n",
    "    sources = []\n",
    "    for msg in state[\"messages\"]:\n",
    "        if msg.type == \"tool\":\n",
    "            try:\n",
    "                content_dict = eval(msg.content) if isinstance(msg.content, str) else msg.content\n",
    "                for src in content_dict.get(\"sources\", []):\n",
    "                    if src not in sources:\n",
    "                        sources.append(src)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return sources\n",
    "\n",
    "def run_query(user_query: str):\n",
    "    state = {\"messages\": [{\"role\": \"user\", \"content\": user_query}]}\n",
    "    final_state = graph.invoke(state, config=config)\n",
    "    final_msg = final_state[\"messages\"][-1]\n",
    "    return {\n",
    "        \"answer\": final_msg.content,\n",
    "        \"sources\": extract_sources(final_state)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cff1d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_query(\"What is the average number of cars in the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d10640a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_query(\"What are benefits of GraphQL in SaaS?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01c04307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== [QUERY OR RESPOND] ====\n",
      "GraphQL allows SaaS applications to fetch exactly the data they need, reducing over-fetching and under-fetching. It enables faster front-end development due to predictable APIs and strong typing. Its introspection features and tooling improve developer productivity.\n"
     ]
    }
   ],
   "source": [
    "def stream_query_notebook(user_query: str, delay: float = 0.05):\n",
    "    state = {\"messages\": [{\"type\": \"human\", \"content\": user_query}]}\n",
    "    config = {\"configurable\": {\"thread_id\": \"notebook-stream\"}}\n",
    "\n",
    "    for token_chunk, metadata in graph.stream(\n",
    "        state,\n",
    "        config=config,\n",
    "        stream_mode=\"messages\"\n",
    "    ):\n",
    "        print(token_chunk.content, end=\"\", flush=True)\n",
    "        time.sleep(delay)  # ⏱️ delay between tokens\n",
    "    print()\n",
    "\n",
    "# Test it\n",
    "stream_query_notebook(\"What are the benefits of GraphQL in SaaS?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b92683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_23604\\1061385911.py:10: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, Text, DateTime\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from datetime import datetime\n",
    "\n",
    "DATABASE_URL = \"postgresql+psycopg2://postgres:1234@localhost:5432/perceivenow_db\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "SessionLocal = sessionmaker(bind=engine)\n",
    "Base = declarative_base()\n",
    "\n",
    "class QueryLog(Base):\n",
    "    __tablename__ = \"query_logs\"\n",
    "\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    query = Column(Text)\n",
    "    answer = Column(Text)\n",
    "    sources = Column(Text)\n",
    "    timestamp = Column(DateTime, default=datetime.utcnow)\n",
    "\n",
    "Base.metadata.create_all(bind=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41bb5fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logged successfully\n"
     ]
    }
   ],
   "source": [
    "from llm_agent import log_query\n",
    "test_query = \"What is GraphQL?\"\n",
    "test_answer = \"GraphQL is a query language for APIs...\"\n",
    "test_sources = [\"doc1.txt\", \"doc4.pdf\"]\n",
    "\n",
    "log_query(test_query, test_answer, test_sources)\n",
    "print(\"✅ Logged successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
